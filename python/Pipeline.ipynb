{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igimjAzTcsPh",
        "outputId": "1dbc311f-f04b-48c8-ec6b-feb2a4c1933a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "LOOKUP_TABLE = {\n",
        "    \"event_date\": {\"date\": parser.parse},\n",
        "    \"device_category\": {\"device_category\": str},\n",
        "    \"geo_country\": {\"country\": str},\n",
        "    \"event_name\": {\"event_name\": str},\n",
        "    \"item_name\": {\"item_name\": str},\n",
        "    \"item_id\": {\"item_id\": str},\n",
        "    \"screen_name\": {\"page_title\": str},\n",
        "    \"firebase_screen\": {\"content\": str},\n",
        "    \"firebase_event_origin\": {\"trigger\": str},\n",
        "    \"content_type\": {\"content_type\": str},\n",
        "    \"firebase_screen_class\": {\"type\": str},\n",
        "    \"ga_session_id\": {\"session_id\": int},\n",
        "    \"ga_session_number\": {\"ga_session_number\": int},\n",
        "    \"skywards_tier\": {\"skywards_tier\": str},\n",
        "    \"event_bundle_sequence_id\": {\"event_count\": int},\n",
        "    \"device_operating_system\": {\"operating_system\": str}\n",
        "}\n",
        "\n",
        "\n",
        "def flatten(root, nested_dict):\n",
        "    new_dict = { f\"{root}_{key}\": nested_dict[key] for key in nested_dict.keys()}\n",
        "\n",
        "    return new_dict\n",
        "\n",
        "\n",
        "def extract(nested_list):\n",
        "    new_dict = {elem['key']: [x for x in elem['value'].values() if x is not None][0]  for elem in nested_list}\n",
        "\n",
        "    return new_dict\n",
        "\n",
        "\n",
        "with open(\"Raw_Data.json\", \"rb\") as f:\n",
        "    content = json.load(f)\n",
        "\n",
        "print(content)\n",
        "\n",
        "records = []\n",
        "reworked_events = []\n",
        "for event in content:\n",
        "    reworked_event = copy.deepcopy(event)\n",
        "    for key in event.keys():\n",
        "        try:\n",
        "            # Flatten all nested dict\n",
        "            if type(event[key]) == dict:\n",
        "                reworked_event.update(flatten(key, event[key]))\n",
        "                del reworked_event[key]\n",
        "        except Exception as e:\n",
        "            print(\"Nested dictionaries have now a different structure than expected\")\n",
        "            raise e\n",
        "\n",
        "        try:\n",
        "            # Extract all list\n",
        "            if type(event[key]) == list:\n",
        "                reworked_event.update(extract(event[key]))\n",
        "                del reworked_event[key]\n",
        "        except Exception as e:\n",
        "            print(\"List values have now a different format than expected\")\n",
        "            raise e\n",
        "\n",
        "    reworked_events.append(reworked_event)\n",
        "    tmp_dict={}\n",
        "    for key in LOOKUP_TABLE.keys():\n",
        "        rename_key = list(LOOKUP_TABLE[key].keys())[0]\n",
        "        tmp_dict[rename_key] = reworked_event.get(key)\n",
        "        if reworked_event.get(key) is not None:\n",
        "            tmp_dict[rename_key] = LOOKUP_TABLE[key][rename_key](reworked_event.get(key))\n",
        "\n",
        "    tmp_dict[\"downloads\"] = 1 if tmp_dict[\"event_count\"] == 1 else None\n",
        "    records.append(tmp_dict)\n",
        "\n",
        "# Uncomment below to check intermediate reworked event\n",
        "# df = pd.DataFrame.from_records(reworked_events)\n",
        "# df.to_csv(\"reworked_events.csv\")\n",
        "\n",
        "print(\"Results:\")\n",
        "print(f\"Event Processed: {len(reworked_events)}\")\n",
        "print(f\"Event Accepted: {len(records)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NUIUhmtTcjSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_records(records)\n",
        "\n",
        "null_values = df.isnull()\n",
        "null_counts = null_values.sum()\n",
        "\n",
        "print(\"Table null values:\")\n",
        "print(null_counts)\n",
        "\n",
        "print(\"Check 'flat_table.csv' for final results\")\n",
        "df.to_csv(\"flat_table.csv\")\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "5fUv6Z39cqPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b1fqvYYedAdr"
      }
    }
  ]
}